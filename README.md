# ADAM_Project
- В последние годы адаптивные методы оптимизации приобрели огромную популярность. Связано это с их эффективностью в машинном обучении. Важно отметить, что в таких методах используется не просто адаптивный подбор шага, а целая матрица шкалирования, которая “подбирает шаг” метода по каждой из переменных оптимизации. Самым известным методом со шкалированием является Adam, но он был далеко не первый, и на самом деле Adam является “докруткой” метода, который придумали за несколько лет до него и просто показали на Курсере. Более того, оригинальная статья про Adam (десятки тысяч цитирований) содержит некорректный теоретический анализ. В этой теме предлагается разобраться в адаптивных методах шкалирования.
- Целью проекта является:
   - провести анализ оригинальной статьи
   - перевести её на русский язык
   - также провести подробный анализ всех утверждений и теорем, использованных в ней
   - провести эксперименты, необходимые для проверки соответствующих гипотез
